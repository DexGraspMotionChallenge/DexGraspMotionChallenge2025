seed: -1

clip_observations: 5.0
clip_actions: 1.0

data_dir: ./dataset
obj_glob_feat_file: ./object_code_glob_feat.npy

seq_num: 1000

policy:
  actor_critic: "ActorCriticDexRep"
  pi_hid_sizes: [1024, 1024, 512, 512]
  vf_hid_sizes: [1024, 1024, 512, 512]
  activation: elu

encoder: # None
  name: graspM3-dexrep-dp3-objnum1-seqnum40
  pretrain_dir: "model/vitac/model_and_config"
  freeze: True
  emb_dim: 128
  en_mode: patch
  f_ex_mode: null
  n_obs_steps: 1

  bn_type: "part"

learn:

  agent_name: shadow_hand
  test: False
  resume: 0
  # check for potential saves every this many iterations
  save_interval: 1000 # 500
  print_log: True

  # rollout params
  max_iterations: 10000000

  # training params
  cliprange: 0.2
  ent_coef: 0
  nsteps: 8
  noptepochs: 5
  nminibatches: 4 # this is per agent
  max_grad_norm: 1
  optim_stepsize: 3.e-4 # 3e-4 is default for single agent training with constant schedule
  schedule: adaptive # could be adaptive or linear or fixed
  desired_kl: 0.016
  gamma: 0.96
  lam: 0.95
  init_noise_std: 0.8 #0.8

  log_interval: 1
  asymmetric: False